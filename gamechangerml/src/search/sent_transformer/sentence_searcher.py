from txtai.embeddings import Embeddings
from numpy import interp
from gamechangerml.api.utils.logger import logger
from gamechangerml.src.search.sent_transformer.utils.files import (
    SentenceTransformerFiles,
)
from gamechangerml.src.text_handling.process import preprocess
from gamechangerml.src.configs import EmbedderConfig
from gamechangerml.src.search.sent_transformer import SimilarityRanker


class SentenceSearcher(object):
    """Imports the index generated by the SentenceEncoder and performs  
    search functionality. 
    
    Initial set of documents are first retrieved from the ANNOY index, and then 
    are ranked with the SimilarityRanker model.

    Args:
        index_path (str): Path to index directory generated by the
            SentenceEncoder.
        sim_model_path (str): Path to the similarity model to load. The model
            should be supported by huggingface and txtai. The model
            is used to calculate similarity between queries and documents.
    """

    def __init__(self, index_path, sim_model_path):
        self.embedder = Embeddings().load(index_path)
        self.data = SentenceTransformerFiles.load_data(index_path)
        self.auto_threshold = self.determine_auto_threshold(index_path, logger)
        logger.info(
            f"SentenceSearcher auto threshold set to {self.auto_threshold}."
        )
        self.similarity = SimilarityRanker(sim_model_path)

    def search(
        self,
        query,
        num_results=10,
        preprocess_query=False,
        use_sim_ranker=True,
        threshold="auto",
    ):
        """Search the index and perform similarity score ranking for the top n
        returned documents.

        Args:
            query (str): Get n documents that are most similar to this query.
            n (int, optional): Number of results to return. Defaults to 10.
            preprocess_query (bool, optional): True to preprocess the query,
                False otherwise. Default is False.
            use_sim_ranker (bool, optional): True to use SimilarityRanker to
                re-rank the top n results returned by the embedder, False
                otherwise. Default is True.
            threshold ("auto" or float in (0,1), optional): Only relevant when
                use_sim_ranker is False. Default is "auto".
        Returns:
            list of dict: The top n results as dictionaries with keys "id",
                "text", and "score". If use_sim_ranker is False, the
                dictionaries will also have keys "text_length" and
                "passing_result".
        """
        if preprocess_query:
            query = " ".join(preprocess(query))

        logger.info(f"Sentence searching for: {query}.")

        if len(query) > 2:
            return self.retrieve_topn(
                query, num_results, use_sim_ranker, threshold
            )
        else:
            return []

    def retrieve_topn(
        self, query, n=10, use_sim_ranker=True, threshold="auto"
    ):
        """Get n documents that are most similar to the given query.

        Args:
            query (str): Get n documents that are most similar to this query.
            n (int, optional): Number of results to return. Defaults to 10.
            use_sim_ranker (bool, optional): True to use SimilarityRanker to
                re-rank the top n results returned by the embedder, False
                otherwise. Default is True.
            threshold ("auto" or float in (0,1), optional): Only relevant when
                use_sim_ranker is False. Default is "auto".
        Returns:
            list of dict: The top n results as dictionaries with keys "id",
                "text", and "score". If use_sim_ranker is False, the
                dictionaries will also have keys "text_length" and
                "passing_result".
        """
        top_n = [
            {
                "id": doc_id,
                "text": self.data[
                    self.data["paragraph_id"] == str(doc_id)
                ].iloc[0]["text"],
                "score": score,
            }
            for doc_id, score in self.embedder.search(query, limit=n)
        ]

        if use_sim_ranker:
            top_n = [
                {
                    "id": top_n[idx]["id"],
                    "text": top_n[idx]["text"],
                    "score": score,
                }
                for idx, score in self.similarity.rank(
                    query, [x["text"] for x in top_n]
                )
            ]
        else:
            lengths = [len(x["text"]) for x in top_n]
            length_scores = interp(min(lengths), max(lengths), (0, 0.2))
            cutoff_score = self.verify_threshold(threshold)

            for idx, doc in enumerate(top_n):
                doc["text_length"] = length_scores[idx]
                doc["passing_result"] = (
                    1 if doc["score"] >= cutoff_score else 0
                )

            top_n = sorted(top_n, key=lambda x: x["score"], reverse=True)

        return top_n

    @staticmethod
    def determine_auto_threshold(index_path, logger):
        """Determine the value for the object's auto_threshold attribute.

        Args:
            index_path (str): Path to directory that contains the saved
                embedder.
            logger (logging.Logger)

        Returns:
            float in (0,1)
        """
        try:
            eval_dict = SentenceTransformerFiles.load_most_recent_eval(
                index_path
            )
            threshold = EmbedderConfig.THRESHOLD_MULTIPLIER * float(
                eval_dict["best_threshold"]
            )
        except Exception:
            threshold = EmbedderConfig.DEFAULT_THRESHOLD
            logger.exception(
                "Failed to determine auto threshold for SentenceSearcher. "
                "Using default."
            )

        return threshold

    def verify_threshold(self, threshold):
        """Determines if the given threshold is valid. If it isn't, raises a
        ValueError.

        Valid threshold are:
            - "auto"
            - float in (0,1)

        Args:
            threshold (any): The threshold to verify.

        Raises:
            ValueError: If threshold given is invalid.

        Returns:
            float: The threshold as a float.
        """
        error_msg = f"Invalid threshold argument: {threshold}. Threshold must "
        "be 'auto' or a number in (0,1)."

        if type(threshold) == str:
            if threshold == "auto":
                threshold = self.auto_threshold
            else:
                raise ValueError(error_msg)

        try:
            threshold = float(threshold)
        except Exception:
            raise ValueError(error_msg)

        if threshold <= 0 or threshold >= 1:
            raise ValueError(error_msg)

        return threshold
