
log_id: "roberta-gc-predict.log"

# class instantiation
model_name: "roberta-base"
epochs: 1
batch_size: 16
random_state: 42

# update these for your environment
checkpoint_path: ~
tensorboard_path: ~
use_checkpoint: ~

# Training args
num_labels: 2
split: 0.90
warmup_steps: 0
lr: 2.0e-05
weight_decay: 0.0
eps: 1.0e-08
clip_grad_norm: 1.0
drop_last: False
truncate: False

# if ~ (None), the max_seq_len will be computed from
# the encoded text up to 512
max_seq_len: ~
